---
---

@string{NeurIPS = {Conference on Neural Information Processing Systems,}}
@string{ICCV = {International Conference on Computer Vision,}}
@string{CVPR = {Conference on Computer Vision and Pattern Recognition,}}
@string{ACCV = {Asian Conference on Computer Vision,}}

@article{cao2024sparsellmwatermark ,
  title={Less is More: Sparse Watermarking in LLMs with Enhanced Text Quality},
  author={Hoang, Cao-Duy and Le, Hung T. Q. and Chu, Rui and Li, Ping and Zhao, Weijie and Lao, Yingjie and Doan, Khoa D},
  year={2024},
  abstract={With the widespread adoption of Large Language Models (LLMs), concerns about potential misuse have emerged. To this end, watermarking has been adapted to LLM, enabling a simple and effective way to detect and monitor generated text. However, while the existing methods can differentiate between watermarked and unwatermarked text with high accuracy, they often face a trade-off between the quality of the generated text and the effectiveness of the watermarking process. In this work, we present a novel type of LLM watermark, \textit{Sparse Watermark}, which aims to mitigate this trade-off by applying watermarks to a small subset of generated tokens distributed across the text. The key strategy involves anchoring watermarked tokens to words that have specific Part-of-Speech (POS) tags. Our experimental results demonstrate that the proposed watermarking scheme achieves high detectability while generating text that outperforms previous LLM watermarking methods in quality across various tasks.},
  bibtex_show={true},
  abbr={PREPRINT},
  selected={true}
}

@article{nguyen2024wicked ,
  title={Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks},
  author={Nguyen, Quang H and Nguyen, Ngoc-Hieu and Ta, The-Anh and Nguyen-Tang, Thanh and Wong, Kok-Seng and Thanh-Tung, Hoang and Doan, Khoa D},
  year={2024},
  abstract={Deep neural networks are vulnerable to backdoor attacks, a type of adversarial attack that poisons the training data to manipulate the behavior of models trained on such data. Clean-label attacks are a more stealthy form of backdoor attacks that can perform the attack without changing the labels of poisoned data. Early works on clean-label attacks added triggers to a random subset of the training set, ignoring the fact that samples contribute unequally to the attack's success. This results in high poisoning rates and low attack success rates. To alleviate the problem, several supervised learning-based sample selection strategies have been proposed. However, these methods assume access to the entire labeled training set and require training, which is expensive and may not always be practical. This work studies a new and more practical (but also more challenging) threat model where the attacker only provides data for the target class (e.g., in face recognition systems) and has no knowledge of the victim model or any other classes in the training set. We study different strategies for selectively poisoning a small set of training samples in the target class to boost the attack success rate in this setting. Our threat model poses a serious threat in training machine learning models with third-party datasets, since the attack can be performed effectively with limited information. Experiments on benchmark datasets illustrate the effectiveness of our strategies in improving clean-label backdoor attacks.},
  bibtex_show={true},
  abbr={PREPRINT},
  pdf={https://arxiv.org/abs/2407.10825},
  selected={false}
}

@article{nguyen2024metallm ,
  title={MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs},
  author={Nguyen, Quang H and Hoang, Cao-Duy and Decugis, Juliette and Manchanda, Saurav and Chawla, Nitesh V and Doan, Khoa D},
  year={2024},
  abstract={The rapid progress in machine learning (ML) has brought forth many large language models (LLMs) that excel in various tasks and areas. These LLMs come with different abilities and costs in terms of computation or pricing. Since the demand for each query can vary, e.g., because of the queried domain or its complexity, defaulting to one LLM in an application is not usually the best choice, whether it is the biggest, priciest, or even the one with the best average test performance. Consequently, picking the right LLM that is both accurate and cost-effective for an application remains a challenge. In this paper, we introduce MetaLLM, a framework that dynamically and intelligently routes each query to the optimal LLM (among several available LLMs) for classification tasks, achieving significantly improved accuracy and cost-effectiveness. By framing the selection problem as a multi-armed bandit, MetaLLM balances prediction accuracy and cost efficiency under uncertainty. Our experiments, conducted on popular LLM platforms such as OpenAI's GPT models, Amazon's Titan, Anthropic's Claude, and Meta's LLaMa, showcase MetaLLM's efficacy in real-world scenarios, laying the groundwork for future extensions beyond classification tasks.},
  bibtex_show={true},
  abbr={PREPRINT},
  pdf={https://arxiv.org/abs/2407.10834},
  code={https://github.com/mail-research/MetaLLM-wrapper/}, 
  selected={true}
}

@article{nguyen2024irl ,
  title={Forget but Recall: Incremental Latent Rectification in Continual Learning},
  author={Nguyen, Nghia D and Nguyen, Hieu T and Li, Ang and Pham, Hoang V and Nguyen, Viet Anh and Doan, Khoa D},
  year={2024},

  bibtex_show={true},
  abbr={PREPRINT},
  pdf={https://arxiv.org/abs/2312.03419},
  selected={true}
}

@inproceedings{nguyen2024cold ,
  title={Cold-start Recommendation by Personalized Embedding Region Elicitation},
  author={Nguyen, Hieu Trung and Nguyen, Duy and Doan, Khoa D and Nguyen, Viet Anh},
  booktitle={The Conference on Uncertainty in Artificial Intelligence},
  year={2023},

  bibtex_show={true},
  abbr={UAI},
  pdf={https://arxiv.org/pdf/2406.00973},
  submissions={RecSys'23 -- CIKM'23 -- AAAI'24 -- UAI'24},
  selected={true}
}

@article{yang2023synthesizing,
  title={Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models},
  author={Yang, Sze Jue and La, Chinh D and Nguyen, Quang H and Bagdasaryan, Eugene and Wong, Kok-Seng and Tran, Anh T and Chan, Chee Seng and Doan, Khoa D},
  year={2024},
  
  bibtex_show={true},
  selected={true},
  abbr={PREPRINT},
  code={https://github.com/mail-research/synthetic-physical-backdoor-datasets},
  pdf={https://arxiv.org/abs/2312.03419}
}


@inproceedings{hung2023clean,
  title={Clean-label Backdoor Attacks by Selectively Poisoning with Limited Information from Target Class},
  author={Nguyen, Quang H and Nguyen, Ngoc-Hieu and Ta, The-Anh and Nguyen, Thanh T and Hoang, Thanh-Tung and Doan, Khoa D},
  booktitle={NeurIPS 2023 Workshop on Backdoors in Deep Learning-The Good, the Bad, and the Ugly},
  year={2023},

  bibtex_show={true},
  abbr={NeurIPS-W},
  pdf={https://openreview.net/forum?id=JvUuutHa2s&noteId=dtKPNhZu9V},
  selected={false}
}

@article{huynh2023fmn,
  title={Forget-Me-Not: Making Backdoor Hard to be Forgotten in Fine-tuning},
  author={Huynh, Tran Ngoc and Tran, Anh T and Doan, Khoa D and Pham, Tung},
  year={2024},
  
  bibtex_show={true},
  abbr={PREPRINT},
  pdf={https://openreview.net/forum?id=T23HYw6lta},
  selected={false}
}

@inproceedings{hoang2023advfooler,
  title={Fooling the Textual Fooler via Randomizing Latent Representations},
  author={Hoang, Cao-Duy and Nguyen, Quang H and Manchanda, Saurav and Peng, Minlong and Wong, Kok-Seng and Doan, Khoa D},
  year={2024},
  
  abbr={ACL-Findings},
  bibtex_show={true},
  booktitle={Findings of the Association for Computational Linguistics},  
  pdf={https://arxiv.org/abs/2310.01452},
  code={https://github.com/mail-research/AdvFooler-text-defender},
  submissions={EMNLP'24 -- ICLR'24 -- ACL'24},
  selected={true}
}  
  


@article{yang2023lossybackdoors,
  title={Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack},
  author={Yang, Sze Jue and Nguyen, Quang H and Chan, Chee Seng and Doan, Khoa D},
  journal={arXiv preprint arXiv:2308.16684},
  year={2024},

  bibtex_show={true},
  abbr={PREPRINT},
  pdf={https://arxiv.org/abs/2308.16684},
  selected={false}
}


@article{doan2022coophash,
  title={CoopHash: Cooperative Learning of Multipurpose Descriptor and Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image Hashing},
  author={Doan, Khoa D and Xie, Jianwen and Zhu, Yaxuan and Zhao, Yang and Li, Ping},
  year={2024},

  bibtex_show={true},
  selected={false},
  abbr={PREPRINT},
  pdf={https://arxiv.org/abs/2210.04288}
}

@inproceedings{nguyen2023randomized,
  title={Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks},
  author={Nguyen, Quang H and Lao, Yingjie and Pham, Tung and Wong, Kok-Seng and Doan, Khoa D},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},

  bibtex_show={true},
  abbr={ICLR},
  pdf={https://openreview.net/forum?id=vZ6r9GMT1n},
  selected={true},
  submissions={NeurIPS'23 -- ICLR'24},
  abstract={Recent works have shown that deep neural networks are vulnerable to adversarial examples that find samples close to the original image but can make the model misclassify. Even with access only to the model's output, an attacker can employ black-box attacks to generate such adversarial examples. In this work, we propose a simple and lightweight defense against black-box attacks by adding random noise to hidden features at intermediate layers of the model at inference time. Our theoretical analysis confirms that this method effectively enhances the model's resilience against both score-based and decision-based black-box attacks. Importantly, our defense does not necessitate adversarial training and has minimal impact on accuracy, rendering it applicable to any pre-trained model. Our analysis also reveals the significance of selectively adding noise to different parts of the model based on the gradient of the adversarial objective function, which can be varied during the attack. We demonstrate the robustness of our defense against multiple black-box attacks through extensive empirical experiments involving diverse models with various architectures.},
}

@article{nguyen2024iba,
  title={Iba: Towards irreversible backdoor attacks in federated learning},
  author={Nguyen, Thuy Dung and Nguyen, Tuan M and Tran, Anh T and Doan, Khoa D and Wong, Kok-Seng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024},

  submissions={NeurIPS'23},
  bibtex_show={true},
  abbr={NeurIPS},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html},
  code={https://github.com/sail-research/iba},
  selected={true}
}

@article{nguyen2024backdoor,
  title={Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions},
  author={Nguyen, Thuy Dung and Nguyen, Tuan M and Le Nguyen, Phi and Pham, Hieu H and Doan, Khoa D and Wong, Kok-Seng},
  journal={Engineering Applications of Artificial Intelligence},
  volume={127},
  pages={107166},
  year={2024},
  publisher={Elsevier},

  submissions={EAAI'24},
  bibtex_show={true},
  abbr={EAAI},
  pdf={https://www.sciencedirect.com/science/article/pii/S0952197623013507},
  selected={true}
}

@inproceedings{nguyen2023empirical,
  title={Empirical Study of Federated Unlearning: Efficiency and Effectiveness},
  author={Nguyen, Thai-Hung and Vu, Hong-Phuc and Nguyen, Dung Thuy and Nguyen, Tuan Minh and Doan, Khoa D and Wong, Kok-Seng},
  booktitle={Asian Conference on Machine Learning},
  pages={959--974},
  year={2023},
  organization={PMLR},

  submissions={ACML'23},
  bibtex_show={true},
  abbr={ACML},
  pdf={https://proceedings.mlr.press/v222/nguyen24a.html},
  selected={false}
}


@inproceedings{doan2023flora,
  bibtex_show={true},
  abbr={SIGIR},
  title={Asymmetric Hashing for Fast Ranking via Neural Network Measures},
  author={Doan, Khoa D and Tan, Shulong and Zhao, Weijie and Li, Ping},
  booktitle={46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2023},
  submissions={SIGIR'21 -- RecSys'21 -- WSDM'22 -- WWW'22 -- SIGIR'22 -- VLDB'23 -- CIKM'22 -- WWW'23 -- SIGIR'23},
  pdf={https://dl.acm.org/doi/abs/10.1145/3539618.3591640},
  selected={true},
}

@inproceedings{doan2023bdvits,
  bibtex_show={true},
  abbr={ICML-W},
  title={A Cosine Similarity-based Method for Out-of-Distribution Detection},
  author={Nguyen, Ngoc-Hieu and Nguyen, Quang H and Nguyen, Thanh T and Doan, Khoa D and Hoang, Thanh-Tung},
  booktitle={ICML 2023 Workshop on Spurious Correlations, Invariance, and Stability},
  year={2023},
  pdf={https://arxiv.org/pdf/2306.14920.pdf},
  teaser={none.png},
  selected={false},
}

@inproceedings{doan2023bdvits,
  abbr={AAAI},
  title={Defending backdoor attacks on vision transformer via patch processing},
  author={Doan, Khoa D and Lao, Yingjie and Li, Ping},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2023},
  
  submissions={CVPR'22 -- ICCV'22 -- AAAI'23},
  bibtex_show={true},
  selected={true},
  teaser={doan2023bdvits.png},
  pdf={https://ojs.aaai.org/index.php/AAAI/article/view/25125},
}

@inproceedings{doan2022genhash,
  title={Unified Learning of Multipurpose Energy Based Generative Hashing Network},
  author={Doan, Khoa D and Reddy, Chandan K},
  booktitle={Sixteenth Asian Conference on Computer Vision},
  year={2022},

  bibtex_show={true},
  abbr={ACCV},
  submissions={TPAMI'21 -- ACCV'22},
  selected={false},
}

@inproceedings{doan2022marksman,
  bibtex_show={true},
  abbr={NeurIPS},
  title={Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class},
  author={Doan, Khoa D and Lao, Yingjie and Li, Ping},
  booktitle={Thirty-Sixth Conference on Neural Information Processing Systems},
  year={2022},
  
  submissions={NeurIPS'22},
  teaser={doan2022marksman.png},
  pdf={https://openreview.net/forum?id=i-k6J4VkCDq},
  code={https://github.com/khoadoan106/backdoor_attacks},
  slides={https://nips.cc/media/neurips-2022/Slides/52924.pdf},
  selected={true},
}

@inproceedings{doan2022hswd,
  bibtex_show={true},
  abbr={CVPR},
  title={One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching},
  author={Doan, Khoa D and Yang, Peng and Li, Ping},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2022},

  submissions={CVPR'22},
  slides={doan2022hswd-slides.pdf},
  code={https://github.com/khoadoan106/single_loss_quantization},
  pdf={https://openreview.net/pdf?id=uaqweIZ-9_k},
  teaser={doan2022hswd.png},
  selected={true},
}

@inproceedings{doan2021wb,
  bibtex_show={true},
  abbr={NeurIPS},
  title={Backdoor Attack with Imperceptible Input and Latent Modification},
  author={Doan, Khoa D and Lao, Yingjie and Li, Ping},
  booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
  year={2021},

  submissions={NeurIPS'21},
  pdf={https://proceedings.neurips.cc/paper/2021/file/9d99197e2ebf03fc388d09f1e94af89b-Paper.pdf},
  code={https://github.com/khoadoan106/backdoor_attacks},
  video={https://recorder-v3.slideslive.com/?share=51522&s=8af881c0-56e8-451e-865f-adb1e90e5471},
  slides={doan2021wb-slides.pdf},
  teaser={doan2021wb.png},
  selected={true},
}

@inproceedings{doan2021lira,
  bibtex_show={true},
  abbr={ICCV},
  title={LIRA: Learnable, Imperceptible and Robust Backdoor Attacks},
  author={Doan, Khoa D and Lao, Yingjie and Zhao, Weijie and Li, Ping},
  booktitle={International Conference on Computer Vision},

  submissions={ICCV'21},
  code={https://github.com/khoadoan106/backdoor_attacks},
  slides={https://github.com/sunbelbd/invisible_backdoor_attacks/raw/master/resources/ICCV2021-LIRA-Slides.pdf},
  poster={https://github.com/sunbelbd/invisible_backdoor_attacks/raw/master/resources/ICCV2021-LIRA-Poster.pdf},
  pdf={https://openaccess.thecvf.com/content/ICCV2021/papers/Doan_LIRA_Learnable_Imperceptible_and_Robust_Backdoor_Attacks_ICCV_2021_paper.pdf},

  year={2021},

  abstract={Recently, machine learning models have demonstrated to be vulnerable to backdoor attacks, primarily due to the lack of transparency in black-box models such as deep neural networks. A third-party model can be poisoned such that it works adequately in normal conditions but behaves maliciously on samples with specific trigger patterns. However, the trigger injection function is manually defined in most existing backdoor attack methods, e.g., placing a small patch of pixels on an image or slightly deforming the image before poisoning the model. This results in a two-stage approach with a sub-optimal attack success rate and a lack of complete stealthiness under human inspection.

  In this paper, we propose a novel and stealthy backdoor attack framework, LIRA, which jointly learns the optimal, stealthy trigger injection function and poisons the model. We formulate such an objective as a non-convex, constrained optimization problem. Under this optimization framework, the trigger generator function will learn to manipulate the input with imperceptible noise to preserve the model performance on the clean data and maximize the attack success rate on the poisoned data. Then, we solve this challenging optimization problem with an efficient, two-stage stochastic optimization procedure. Finally, the proposed attack framework achieves 100% success rates in several benchmark datasets, including MNIST, CIFAR10, GTSRB, and T-ImageNet, while simultaneously bypassing existing backdoor defense methods and human inspection.
  },

  teaser={doan2021lira.png},

  selected={true},
}


@inproceedings{doan2021interpretable,
  bibtex_show={true},
  abbr={SIGIR},
  url={https://dl.acm.org/doi/abs/10.1145/3404835.3462960},
  code={https://github.com/khoadoan/GraphOTSim},
  pdf={doan2021interpretable.pdf},
  slides={https://github.com/khoadoan/GraphOTSim/raw/main/resources/SIGIR21-fp0937-slides.pdf},
  video={https://www.youtube.com/watch?v=IWxxsuFPsgs&t=1s},
  teaser={doan2021interpretable.png},
  selected={true},

  submissions={AAAI'21 -- WWW'21 -- SIGIR'21},
  author = {Doan, Khoa D and Manchanda, Saurav and Mahapatra, Suchismit and Reddy, Chandan K},
  title = {Interpretable Graph Similarity Computation via Differentiable Optimal Alignment of Node Embeddings},
  year = {2021},
  isbn = {9781450380379},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3404835.3462960},
  doi = {10.1145/3404835.3462960},
  abstract = {Computing graph similarity is an important task in many graph-related applications
  such as retrieval in graph databases or graph clustering. While numerous measures
  have been proposed to capture the similarity between a pair of graphs, Graph Edit
  Distance (GED) and Maximum Common Subgraphs (MCS) are the two widely used measures
  in practice. GED and MCS are domain-agnostic measures of structural similarity between
  the graphs and define the similarity as a function of pairwise alignment of different
  entities (such as nodes, edges, and subgraphs) in the two graphs. The explicit explainability
  offered by the pairwise alignment provides transparency and justification of the similarity
  score, thus, GED and MCS have important practical applications. However, their exact
  computations are known to be NP-hard. While recently proposed neural-network based
  approximations have been shown to accurately compute these similarity scores, they
  have limited ability in providing comprehensive explanations compared to classical
  combinatorial algorithms, e.g., Beam search. This paper aims at efficiently approximating
  these domain-agnostic similarity measures through a neural network, and simultaneously
  learning the alignments (i.e., explanations) similar to those of classical intractable
  methods. Specifically, we formulate the similarity between a pair of graphs as the
  minimal "transformation" cost from one graph to another in the learnable node-embedding
  space. We show that, if node embedding is able to capture its neighborhood context
  closely, our proposed similarity function closely approximates both the alignment
  and the similarity score of classical methods. Furthermore, we also propose an efficient
  differentiable computation of our proposed objective for model training. Empirically,
  we demonstrate that the proposed method achieves up to 50%-100% reduction in the Mean
  Squared Error for the graph similarity approximation task and up to 20% improvement
  in the retrieval evaluation metrics for the graph retrieval task. The source code
  is available at https://github.com/khoadoan/GraphOTSim.},
  booktitle = {44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages = {665–674},
  numpages = {10},
  keywords = {similarity search, model interpretability, graph similarity, GCN},
  location = {Virtual Event, Canada},
  series = {SIGIR '21}
}

@inproceedings{doan2020efficient,
  bibtex_show={true},
  abbr={WWW},
  url={https://dl.acm.org/doi/abs/10.1145/3366423.3380150},
  html={https://dl.acm.org/doi/abs/10.1145/3366423.3380150},
  pdf={https://people.cs.vt.edu/~reddy/papers/WWW20a.pdf},
  teaser={doan2020efficient.png},
  selected={true},

  author = {Doan, Khoa D and Reddy, Chandan K},
  title = {Efficient Implicit Unsupervised Text Hashing Using Adversarial Autoencoder},
  year = {2020},
  isbn = {9781450370233},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3366423.3380150},
  doi = {10.1145/3366423.3380150},
  abstract = {Searching for documents with semantically similar content is a fundamental problem
  in the information retrieval domain with various challenges, primarily, in terms of
  efficiency and effectiveness. Despite the promise of modeling structured dependencies
  in documents, several existing text hashing methods lack an efficient mechanism to
  incorporate such vital information. Additionally, the desired characteristics of an
  ideal hash function, such as robustness to noise, low quantization error and bit balance/uncorrelation,
  are not effectively learned with existing methods. This is because of the requirement
  to either tune additional hyper-parameters or optimize these heuristically and explicitly
  constructed cost functions. In this paper, we propose a Denoising Adversarial Binary
  Autoencoder (DABA) model which presents a novel representation learning framework
  that captures structured representation of text documents in the learned hash function.
  Also, adversarial training provides an alternative direction to implicitly learn a
  hash function that captures all the desired characteristics of an ideal hash function.
  Essentially, DABA adopts a novel single-optimization adversarial training procedure
  that minimizes the Wasserstein distance in its primal domain to regularize the encoder’s
  output of either a recurrent neural network or a convolutional autoencoder. We empirically
  demonstrate the effectiveness of our proposed method in capturing the intrinsic semantic
  manifold of the related documents. The proposed method outperforms the current state-of-the-art
  shallow and deep unsupervised hashing methods for the document retrieval task on several
  prominent document collections.},
  booktitle = {Proceedings of The Web Conference},
  pages = {684–694},
  numpages = {11},
  keywords = {autoencoder, Hashing, adversarial training, deep learning.},
  location = {Taipei, Taiwan},
  series = {WWW '20}
}

@article{doan2020imagegen,
  bibtex_show={true},
  abbr={arXiv},
  title={Image Generation Via Minimizing Fréchet Distance in Discriminator Feature Space},
  author={Doan, Khoa D and Manchanda, Saurav and Wang, Fengjiao and Selvaraj, Sathiya K and Bhowmik, Avradeep and Reddy, Chandan K},
  journal={arXiv preprint arXiv:2003.11774},
  year={2020}
}

@article{doan2020imagehash,
  bibtex_show={true},
  abbr={arXiv},
  title={Image Hashing by Minimizing Discrete Component-wise Wasserstein Distance},
  author={Doan, Khoa D and Manchanda, Saurav and Badirli, Sarkhan and Reddy, Chandan K},
  journal={arXiv preprint arXiv:2003.00134},
  year={2020}
}

@article{manchanda2020regression,
  bibtex_show={true},
  abbr={arXiv},
  title={Regression via implicit models and optimal transport cost minimization},
  author={Manchanda, Saurav and Doan, Khoa D and Yadav, Pranjul and Selvaraj, Sathiya K},
  journal={arXiv preprint arXiv:2003.01296},
  year={2020}
}

@article{badirli2020gradient,
  bibtex_show={true},
  abbr={arXiv},
  url={https://arxiv.org/abs/2002.07971},
  code={https://github.com/sbadirli/GrowNet},
  pdf={https://arxiv.org/pdf/2002.07971.pdf},
  teaser={badirli2020gradient.png},
  selected={true},

  title={Gradient boosting neural networks: Grownet},
  abstract={A novel gradient boosting framework is proposed where shallow neural networks are employed as ``weak learners''. General loss functions are considered under this unified framework with specific examples presented for classification, regression, and learning to rank. A fully corrective step is incorporated to remedy the pitfall of greedy function approximation of classic gradient boosting decision tree. The proposed model rendered outperforming results against state-of-the-art boosting methods in all three tasks on multiple datasets. An ablation study is performed to shed light on the effect of each model components and model hyperparameters.},
  author={Badirli, Sarkhan and Liu, Xuanqing and Xing, Zhengming and Bhowmik, Avradeep and Doan, Khoa D and Selvaraj, Sathiya K},
  journal={arXiv preprint arXiv:2002.07971},
  year={2020},
}

@inproceedings{manchanda2019targeted,
  bibtex_show={true},
  abbr={BigData},
  title={Targeted display advertising: the case of preferential attachment},
  author={Manchanda, Saurav and Yadav, Pranjul and Doan, Khoa D and Selvaraj, Sathiya K},
  booktitle={Proceedings of the 2019 IEEE International Conference on Big Data},
  pages={1868--1877},
  year={2019},
  organization={IEEE}
}

@inproceedings{doan2019adversarial,
  bibtex_show={true},
  abbr={CIKM},
  pdf={https://dmkd.cs.vt.edu/papers/CIKM19.pdf},
  teaser={doan2019adversarial.png},
  selected={true},

  author = {Doan, Khoa D and Yadav, Pranjul and Reddy, Chandan K},
  title = {Adversarial Factorization Autoencoder for Look-Alike Modeling},
  year = {2019},
  isbn = {9781450369763},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3357384.3357807},
  doi = {10.1145/3357384.3357807},
  abstract = {Digital advertising is performed in multiple ways, for e.g., contextual, display-based
  and search-based advertising. Across these avenues, the primary goal of the advertiser
  is to maximize the return on investment. To realize this, the advertiser often aims
  to target the advertisements towards a targeted set of audience as this set has a
  high likelihood to respond positively towards the advertisements. One such form of
  tailored and personalized, targeted advertising is known as look-alike modeling, where
  the advertiser provides a set of seed users and expects the machine learning model
  to identify a new set of users such that the newly identified set is similar to the
  seed-set with respect to the online purchasing activity. Existing look-alike modeling
  techniques (i.e., similarity-based and regression-based) suffer from serious limitations
  due to the implicit constraints induced during modeling. In addition, the high-dimensional
  and sparse nature of the advertising data increases the complexity. To overcome these
  limitations, in this paper, we propose a novel Adversarial Factorization Autoencoder
  that can efficiently learn a binary mapping from sparse, high-dimensional data to
  a binary address space through the use of an adversarial training procedure. We demonstrate
  the effectiveness of our proposed approach on a dataset obtained from a real-world
  setting and also systematically compare the performance of our proposed approach with
  existing look-alike modeling baselines.},
  booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  pages = {2803–2812},
  numpages = {10},
  keywords = {deep learning, autoencoder, hashing, factorization, adversarial training, look-alike modeling},
  location = {Beijing, China},
  series = {CIKM '19}
}

@inproceedings{doan2019attentive,
  abbr={PAKDD},
  title={An Attentive Spatio-Temporal Neural Model for Successive Point of Interest Recommendation.},
  author={Doan, Khoa D and Yang, Guolei and Reddy, Chandan K},
  booktitle={Proceedings of the 2019 Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)},
  pages={346--358},
  year={2019}
}

@inproceedings{kuo2017quest,
  bibtex_show={true},
  abbr={BigData},
  title={Quest for Value in Big Earth Data},
  author={Kuo, Kwo-Sen and Oloso, Amidu O and Rilee, Mike L and Doan, Khoa D and Clune, Thomas L and Yu, Hongfeng},
  booktitle={EGU General Assembly Conference Abstracts},
  pages={8413},
  year={2017}
}


@inproceedings{doan2016evaluating,
  bibtex_show={true},
  abbr={BigData},
  title={Evaluating the impact of data placement to spark and SciDB with an Earth Science use case},
  author={Doan, Khoa D and Oloso, Amidu O and Kuo, Kwo-Sen and Clune, Thomas L and Yu, Hongfeng and Nelson, Brian and Zhang, Jian},
  booktitle={Proceedings of the 2016 IEEE International Conference on Big Data},
  pages={341--346},
  year={2016},
  organization={IEEE}
}

@inproceedings{kuo2016implications,
  bibtex_show={true},
  abbr={IGARSS},
  title={Implications of data placement strategy to Big Data technologies based on shared-nothing architecture for geosciences},
  author={Kuo, Kwo-Sen and Oloso, Amidu and Doan, Khoa D and Clune, Thomas L and Yu, Hongfeng},
  booktitle={2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  pages={7605--7607},
  year={2016},
  organization={IEEE}
}

@inproceedings{clune2015scidb,
  bibtex_show={true},
  abbr={AGU},
  title={SciDB versus Spark: A preliminary comparison based on an Earth science use case},
  author={Clune, Thomas and Kuo, Kwo-Sen and Doan, Khoa D and Oloso, Amidu},
  booktitle={AGU Fall Meeting Abstracts},
  volume={2015},
  year={2015}
}

@inproceedings{doan2014performance,
  bibtex_show={true},
  abbr={BigData},
  title={Performance comparison of big-data technologies in locating intersections in satellite ground tracks},
  author={Doan, Khoa D and Oloso, Amidu and Kuo, Kwo-Sen and Clune, Thomas L and Bayesics, LLC},
  booktitle={Proceedings of the 2014 ASE BigData/SocialInformatics/PASSAT/BioMedCom Conference},
  year={2014},
  organization={Citeseer}
}

@inproceedings{kuo2013demonstration,
  bibtex_show={true},
  abbr={AGU},
  title={A Demonstration of Big Data Technology for Data Intensive Earth Science},
  author={Kuo, K and Clune, T and Ramachandran, R and Rushing, J and Fekete, G and Lin, A and Doan, KD and Oloso, AO and Duffy, D},
  booktitle={AGU Fall Meeting Abstracts},
  volume={2013},
  year={2013}
}
