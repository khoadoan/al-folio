---
layout: research
title: research
tagline: <span class="font-weight-bold">Machine Learning Algorithms</span> that Make Sense
tagline_desc: in constrained and large-scale settings with applications in <strong>Advertising</strong>, <strong>Healthcare</strong>, <strong>Sustainability</strong> (Climate, Computing, Agricultural), <strong>Social Goods</strong>...
permalink: /research
definition: "<span style='font-size:1.2em'><strong>MAIL</strong></span> stands for <span style='font-size:1.2em'>practical <strong>M</strong>achine <strong>L</strong>earning and <strong>AI</strong> Lab</span>, led by <strong>Dr. Khoa D Doan</strong>."
description: "Here at <strong>MAIL</strong>, We develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on improving the following aspects of existing models: (i) training/inference, (ii) realistic assumptions, (iii) algorithmic robustness, and (iv) efficiency in constrained settings. Most of our ML/AI solutions center around large-scale approaches that have low computational complexity and require less human effort."
research_image: icon-v1.png
nav: true
weight: 10
---

**Selected Press Coverage**:  [khoahocphattrien](https://khoahocphattrien.vn/cong-nghe/bill-melinda-gates-foundation-tai-tro-cho-vinuni-xay-dung-chatbot-cham-soc-suc-khoe-phu-khoa/20230814063044566p1c859.htm)
, [Thanh Nien](https://thanhnien.vn/du-an-khoa-hoc-viet-nam-duoc-to-chuc-quoc-te-tai-tro-1-trieu-bang-anh-185240608100441358.htm), [VnExpress](https://vnexpress.net/nha-khoa-hoc-viet-gianh-giai-thuong-toan-cau-ve-suc-khoe-4756007.html), [BaoDauTu](https://baodautu.vn/vinuni-gianh-giai-thuong-lon-nhat-tri-gia-1-trieu-bang-anh-trong-cuoc-thi-thu-thach-toan-cau-trinity-d217179.html), [DanTri](https://dantri.com.vn/suc-khoe/vinuni-gianh-giai-thuong-cao-nhat-trong-cuoc-thi-thu-thach-trinity-20240608160801634.htm), [Vietnam.vn](https://www.vietnam.vn/vinuni-gianh-giai-thuong-lon-trong-cuoc-thi-toan-cau/), [Vietnam.vn](https://www.vietnam.vn/vinuni-gianh-giai-thuong-lon-trong-cuoc-thi-toan-cau/), [Yahoo Finance](https://sg.finance.yahoo.com/news/vinuni-won-1-million-global-104000008.html), [Benzinga](https://www.benzinga.com/content/39240305/vinuni-won-1-million-global-grand-prize-in-the-trinity-challenge),  [Macau Business](https://www.macaubusiness.com/vinuni-won-1-million-global-grand-prize-in-the-trinity-challenge/), [Taiwan News](https://www.taiwannews.com.tw/news/5886511), [TNGlobal](https://technode.global/2024/06/25/from-science-fiction-to-reality-how-a-vietnamese-ai-platform-powered-by-human-ingenuity-could-save-millions-of-lives/), [VinGroup](https://www.vingroup.net/tin-tuc-su-kien/bai-viet/3124/vinuni-gianh-giai-thuong-lon-nhat-tri-gia-1-trieu-bang-anh-trong-cuoc-thi-thu-thach-toan-cau-trinity)...

<!-- <h5 style="color:red">***Warning: This page is severely out of date. Update coming soon in Summer 2024!</h5> -->

<!-- Here at **MAIL**, We develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on improving the following aspects of existing models: (i) training/inference, (ii) realistic assumptions, (iii) algorithmic robustness, and (iv) efficiency in constrained settings. Most of our ML/AI solutions center around large-scale approaches that have low computational complexity and require less human effort.  -->

<!-- [more about our research](research/) -->

<!-- Khoa D Doan is currently an **Assistant Professor** in the College of Engineering and Computer Science (CECS) at VinUniversity, Vietnam. Previously, he was a **Researcher** in the Cognitive Computing Lab at [Baidu Research](http://research.baidu.com/) working with [Dr. Ping Li](http://research.baidu.com/People/index-view?id=111) on generative modeling and its applications in Information Retrieval and AI Security. He was a member of [Prof. Chandan K. Reddy](https://people.cs.vt.edu/reddy)'s lab at VT and the [Sanghani Center for Artificial Intelligence & Data Analytics](https://sanghani.cs.vt.edu/) since 2016. From May 2019 to Feb 2020, he was at [Criteo AI Lab](https://ailab.criteo.com/) in Palo Alto, CA, where he worked with [Dr. Sathiya Keerthi Selvaraj](http://www.keerthis.com/) and Dr. Fengjiao Wang. Before that, he was a Faculty Research Associate of [Earth System Science Interdisciplinary Center](http://essic.umd.edu/) at [UMD](https://www.umd.edu/) and also had a joint appointment at [NASA Goddard Space Flight Center](https://www.nasa.gov/goddard), where he worked on high-performance and distributed system research. Khoa D Doan received his Ph.D. in Computer Science from [Virginia Polytechnic Institute and State University](cs.vt.edu), and MS in Computer Science from [University of Maryland, College Park](cs.umd.edu). -->

<!-- <h1 class="post-title">{{ "Research Interests"}}</h1><a name="research_interests"></a> -->
# Research Interests
Our research seek answers to the following question: *Are existing ML methods simple to use and reliable for practical uses*? **Simplicity**, given the context where ML is to be deployed, refers to the ability to (i) feasibly build or implement the method, (ii) execute the deployed model efficiently, and (iii) evolve the deployed model with less effort. **Reliability** relates to (i) whether we can rely on the model to solve the intended task well, (ii) whether this performance is preserved under frequently perturbed environments in practice such as data corruptions or distributional changes, and (iii) whether the model is resilient to (i.e., its performance is not significantly affected by) various forms of security attacks such as adversarial examples and causal attacks. In this sense, I believe that many existing ML methods, including those with *complex* deep neural networks (DNNs), are *reliable in ideal and high-resource settings* but *not yet reliable and simple to use given real-world constraints*. The effort to answer this question will help us truly realize the potential of AI/ML methodology in practice, further advancing its societal benefits, especially for many low-resource and low-income communities that have yet equally benefitted from these advancements.

<!-- Our research focuses on understanding the practical limits of using existing ML methods in the real-world. Essential, we seek answers to the following question: *How to make ML models simpler & reliable to use in constrained settings*? **Simplicity** refers to the ability to (i) build or implement the method easily, (ii) execute the deployed model efficiently, and (iii) evolve the deployed model with less effort. **Reliability** relates to (i) whether we can rely on the model to solve the intended task well, (ii) whether this performance is preserved under frequently perturbed environments in practice such as data corruptions or distributional changes, and (iii) whether the model is resilient to (i.e., its performance is not significantly affected by) various forms of security attacks such as adversarial examples and causal attacks. In this sense, we believe that many existing ML methods, including those with *complex* deep neural networks, are *reliable* but *not yet easy-to-use* because they do not satisfy various constraints seen in real-world applications. We also strongly believe the effort to answer this question will help us truly realize the potential of AI/ML methodology in practice.   -->

Our goal, therefore, is to develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on studying and improving the following aspects of existing ML models: (i) **training**, (ii) **inference**, (iii) **realistic assumptions**, and (iv) **security/robustness**. Our current research scope roughly falls into the following areas or themes:
<!-- therefore, is to develop computational frameworks that enable existing complex/deep models to be more suitable for practical uses. We focus on improving the following aspects of existing models: (i) **training/inference**, (ii) **realistic assumptions**, (iii) **algorithmic robustness**, and (iv) **efficiency in constrained settings**. Most of our ML/AI solutions center around generative-based approaches that have low computational complexity and require less human effort. Currently, our research activities include, but not limited to, the following themes (*with selected publications*): -->

<span style='font-size:1.2em'>**Robust Machine Learning**</span>

<!-- We focus in several issues such as security vulnerabilities in training data, training process, and model inference, robust predictions under missing data and OOD scenarios, and vulnerabilities in Federated Learning systems. -->
We first aim to investigate the security and reliability issues of existing ML models under various forms of attacks -- including causative attacks (such as trojan/backdoor attacks) and exploratory attacks (such as adversarial examples) -- and test-time distributional changes, then develop suitable countermeasures and mitigation approaches to ensure their safe and effective deployment in real-world scenarios.  

* Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator (2024 by Nguyen et al)
* Estimating Uncertainties of Multimodal Models with Missing Modalities (2024 Nguyen et al.)
* Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape (2024 by Nguyen et al.)
* Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack
(2024 by Yang et al.)
* Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models (2024 by Yang et al.)
* Flatness-aware Sequential Learning Generates Resilient Backdoors (***ECCV*** 2024 by Pham et al.)
* Data Poisoning Quantization Backdoor Attack (***ECCV*** 2024 by Huynh et al.)
* Composite Concept Extraction through Backdooring (**ICPR*** 2024 by Ghosh et al.)
* Fooling the Textual Fooler via Randomizing Latent Representations (***ACL*** 2024 by Hoang et al.)
* Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks (***ICLR*** 2024 by Nguyen et al.)
* Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions (***EAAI*** 2024 by Nguyen et al.)
* Iba: Towards irreversible backdoor attacks in federated learning (***NeurIPS*** 2023 by Nguyen et al.)
* A Cosine Similarity-based Method for Out-of-Distribution Detection (***ICML-W*** 2023 by Nguyen et al.)
* Clean-label Backdoor Attacks by Selectively Poisoning with Limited Information from Target Class (***NeurIPS-W*** 2023 by Nguyen et al.)
* Defending backdoor attacks on vision transformer via patch processing  (***AAAI*** 2023 by Doan et al.)
* Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class (***NeurIPS*** 2022 by Doan et al.)
* Backdoor Attack with Imperceptible Input and Latent Modification (***NeurIPS*** 2021 by Doan et al.)
* LIRA: Learnable, Imperceptible and Robust Backdoor Attacks (***ICCV*** 2021 by Doan et al.)

<span style='font-size:1.2em'>**Practical Information Retrieval**</span>

<!-- We focus in hashing-based methods and retrieval with complex, non-metric measures. -->
We aim to develop retrieval models, especially the hashing/quantization techniques, that (i) can be trained efficiently on large-scale data, (ii) can make inference decisions in real-time, (iii) can generalize well with limited labeled data,  and (iv) have robust inference such as out-of-distribution and missing-data robustness.

* Cooperative Learning of Multipurpose Descriptor and Contrastive Pair Generator via Variational MCMC Teaching for Supervised Image Hashing (2024 by Doan et al)
* Asymmetric Hashing for Fast Ranking via Neural Network Measures  (*SIGIR* 2023 by Doan et al.)
* One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching  (*CVPR* 2022 by Doan et al.)
* Generative Hashing Network (*ACCV* 2022 by Doan et al.)
* Interpretable Graph Similarity Computation via Differentiable Optimal Alignment of Node Embeddings (*SIGIR* 2021 by Doan et al.)
* Image Hashing by Minimizing Discrete Component-wise Wasserstein Distance (2021 by Doan et al.)
* Efficient Implicit Unsupervised Text Hashing using Adversarial Autoencoder (*WWW* 2020 by Doan et al.)

<span style='font-size:1.2em'>**Generative Modeling and its Applications**</span>

<!-- We focus on developing low-resource algorithms for generative AIs. -->

We aim to (i) study and understand the characteristics and principles behind generative models, including generative-adversarial networks, energy-based models, and diffusion models then (ii) develop robust, data-efficient, and/or secured generative-based predictive frameworks, focusing on accelerating security and reliability research in practical applications.

* Unveiling Concept Attribution in Diffusion Models (2024 by Nguyen et al.)
* Sparse Watermarking in LLMs with Enhanced Text Quality (2024 by Hoang et al.)
* Fair Generation in LLMs with RAG (Chu et al.)
* Reward Over-optimization in Direct Alignment Algorithms with Adaptive Learning (2024 by Nguyen et al.)
* Predictive Concept Attribution in Difussion Models (by Nguyen et al.)
* Synthesizing Physical Backdoor Datasets: An Automated Framework Leveraging Deep Generative Models (2024 by Yang et al.)
* Image Generation Via Minimizing Frechet Distance in Discriminator Feature Space (2021 by Doan et al.)

<span style='font-size:1.2em'>**Low-resource Machine Learning**</span>

One of our lifelong passions is to catalyze equitable access to AI tools and approaches in low-resource and low-income communities, starting with the development of high-quality, culture-aware benchmarking systems, and ending with suitable solutions to adapt the existing ML models with satisfactory performance and efficient resource utilization. **This effort will help democratize knowledge in these communities, significantly improving the quality of life of their citizens.**

Consequently, a large part of our research is now devoted to solving various societal challenges with AI in low-resource communities. We're working on problems such as low-resource NLP, low-resource remote-sensing predictive algorithms, cross-cultural language understanding, and visual question answering algorithms for medical domain. For more information, please visit the [Center for Envrionmental Intelligence](https://cei.vinuni.edu.vn/) (**CEI**, where Prof. Khoa D. Doan is currently the Environment Monitoring Lab Director) and [VinUni-Illinois Smart Health Center](https://smarthealth.vinuni.edu.vn/) (**VISHC**, where Prof. Khoa D. Doan is currently the Associate Director)

**VinUni-Illinois Smart Health Center** (<a href="smarthealth.vinuni.edu.vn" id="VISHC">VISHC</a>) --  VISHC is open to collaborate with all researchers and research/industry institutions in Vietnam and around the world. VISHC aims to solve various healthcare related challenges with translational and innovative research. Led by Prof. [Minh Do](https://ece.illinois.edu/about/directory/faculty/minhdo) and Prof. [Helen Nguyen](https://cee.illinois.edu/directory/profile/thn) at UIUC, and Prof. [Khoa D Doan](https://vinuni.edu.vn/people/khoa-d-doan-phd/) at VinUni (*who leads MAIL-Research*), the VISHC's team comprises of world-renowned researchers and talented PhD/Master Students, Research Assistants and Postdocs. Please reach out via [email](mailto:khoa.dd@vinuni.edu.vn) for any collaboration opportunities.

**Center for Environmental Intelligence** (<a href="https://cei.vinuni.edu.vn/" id="CEI">CEI</a>) -- *MAIL-Research is a member of CEI*. CEI represents a pioneering initiative at the intersection of advanced technology, environmental science, and interdisciplinary research and is open for collaboration. Led by Prof. [Laurent El Ghaoui](https://vinuni.edu.vn/people/laurent-el-ghaoui-phd-2/), CEI aims to address critical global sustainability challenges with innovative approaches based on AI. Please reach out via [email](mailto:khoa.dd@vinuni.edu.vn) for any collaboration opportunities, especially those related to *environmental monitoring*.


<!-- <span style='font-size:1.2em'>**AI Backdoor Security with Generative Models**</span>

* Backdoor Attack with Imperceptible Input and Latent Modification (*NeurIPS* 2021 by Doan et al.)
* LIRA: Learnable, Imperceptible and Robust Backdoor Attacks (*ICCV* 2021 by Doan et al.)
* Adversarial Defenses for Vision Transformers   (*Under Submission* 2022 by Peng et al.)
* Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class (*NeurIPS* 2022 by Doan et al.)
* Defending backdoor attacks on vision transformer via patch processing  (*AAAI* 2023 by Doan et al.) -->

<!-- # Industry Interests -->